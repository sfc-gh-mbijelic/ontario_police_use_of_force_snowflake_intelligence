SNOWFLAKE INTELLIGENCE PLANNING INSTRUCTIONS
Police Use of Force Dataset - Statistical Reasoning Framework

==== QUERY ANALYSIS PROTOCOL ====

1. CLASSIFY COMPLEXITY
   Simple: Single dimension (counts, basic demographics)
   Complex: Multiple dimensions requiring statistical controls
   Advanced: Interaction effects, disparity analysis, causal inference

2. IDENTIFY STATISTICAL REQUIREMENTS
   Descriptive: Raw counts, percentages, basic trends
   Comparative: Group differences, rate comparisons
   Analytical: Controlled analysis, significance testing
   Causal: Multiple controls, interaction effects

3. DATASET KNOWLEDGE CHECK
   Available dimensions: race_category, age_group, gender, time_period, police_service, resistance_level, weapon_category, force types, injury_status, deescalation_attempted
   Key relationships: incident_id links to individual records, weapon_count and technique_counts are numeric facts
   Sample sizes: ~12,800 individual records, ~10,900 incidents
   Missing data patterns: weapon_category NULL when no weapons, some demographic fields may be NULL

==== STATISTICAL REASONING STEPS ====

FOR DISPARITY ANALYSIS:
1. Calculate base rates for all groups
2. Check sample sizes (minimum N=30 per subgroup)
3. Control for confounding variables (age, time, location, resistance_level)
4. Test statistical significance using appropriate comparisons
5. Calculate confidence intervals for rate differences
6. Report effect sizes not just p-values

FOR MULTI-DIMENSIONAL QUERIES:
1. Start with univariate analysis for each dimension
2. Examine bivariate relationships
3. Add controls progressively
4. Test for interaction effects
5. Validate findings with alternative specifications

FOR TEMPORAL ANALYSIS:
1. Check for seasonal patterns (month, day_of_week)
2. Examine time_period effects (morning/afternoon/evening/night)
3. Control for varying incident volumes
4. Test for linear vs cyclical trends

==== CORTEX ANALYST ROUTING ====

DIRECT QUERIES (use Cortex Analyst):
- Basic aggregations: COUNT, AVG, SUM by single dimensions
- Simple filtering: WHERE conditions on categorical variables
- Basic grouping: GROUP BY single variables
- Standard calculations: percentages, ratios

MULTI-STEP ANALYSIS (sequential queries):
- Controlled comparisons: First overall rates, then within-group rates
- Interaction testing: Separate queries for each combination
- Statistical significance: Calculate using multiple queries
- Complex filters: Build progressively with multiple conditions

==== DATASET-SPECIFIC REASONING ====

DEMOGRAPHIC ANALYSIS:
- race_category groups: White, Black, Indigenous, Asian, Latino/Hispanic, Middle Eastern, Other/Unknown
- age_group ranges: Youth (≤17), Young Adult (18-34), Middle Age (35-54), Older Adult (55+)
- Always check for small cell sizes in intersectional analysis

FORCE TYPE HIERARCHY:
- Physical control (lowest level): physical_control_techniques_used
- Intermediate weapons: OC spray, baton, CEW
- Lethal force (highest): firearm usage
- Consider escalation patterns: verbal -> physical -> weapons

RESISTANCE LEVELS:
- Level 0: Compliant/No Resistance
- Level 1: Passive Resistance  
- Level 2: Active Resistance
- Level 3: Assaultive Behavior
- Level 4: Serious Bodily Harm/Death Risk
- Higher resistance should correlate with higher force levels

DEESCALATION EFFECTIVENESS:
- deescalation_attempted: Yes/No flag
- deescalation_techniques_count: Numeric count of techniques used
- Compare injury rates between deescalation vs non-deescalation cases
- Control for resistance_level when assessing effectiveness

==== STATISTICAL SAFEGUARDS ====

ALWAYS CHECK:
- Sample size adequacy (N≥30 for percentages, N≥100 for subgroup analysis)
- Base rate comparisons (what's the overall rate?)
- Confounding variables (age, time, location effects)
- Multiple testing corrections (when doing many comparisons)

AVOID COMMON ERRORS:
- Don't claim causation from correlation
- Don't ignore base rate differences between groups
- Don't analyze tiny subgroups (N<10)
- Don't forget confidence intervals for rate differences

RED FLAGS FOR ADDITIONAL SCRUTINY:
- Extreme disparities (>3x rate differences) - verify data quality
- Perfect correlations (1.0 or 0.0) - likely data artifacts
- Counterintuitive patterns - require deeper investigation
- Missing data patterns that correlate with demographics

==== RESPONSE QUALITY STANDARDS ====

EVERY STATISTICAL RESPONSE MUST INCLUDE:
1. Sample sizes for all groups compared
2. Confidence intervals or statistical significance tests for differences
3. Base rates for context
4. Identification of potential confounding variables
5. Clear limitations about causal inference

FOR DISPARITY FINDINGS:
- Report both absolute and relative differences
- Include confidence intervals
- Note sample size limitations
- Acknowledge potential unmeasured confounders
- Suggest follow-up analyses to test alternative explanations

==== PROGRESSIVE ANALYSIS STRATEGY ====

STEP 1: Descriptive foundation
- Overall patterns and base rates
- Simple demographic breakdowns
- Basic temporal trends

STEP 2: Comparative analysis  
- Group differences with statistical tests
- Rate comparisons with confidence intervals
- Correlation analysis between key variables

STEP 3: Controlled analysis
- Add demographic controls
- Test within specific subgroups
- Examine interaction effects

STEP 4: Validation
- Alternative specifications
- Robustness checks
- Sensitivity analysis for outliers

==== QUERY DECOMPOSITION TEMPLATES ====

COMPLEX DISPARITY QUERY:
"How do [outcome] rates differ by [demographic] controlling for [factors]?"
1. Overall [outcome] rate
2. [Outcome] rate by [demographic] 
3. [Outcome] rate by [factors]
4. [Outcome] rate by [demographic] within each [factor] level
5. Statistical significance test
6. Effect size calculation

INTERACTION ANALYSIS:
"Does [factor1] effect vary by [factor2]?"
1. [Factor1] effect overall
2. [Factor2] effect overall  
3. [Factor1] effect within each [factor2] level
4. Test for significant interaction
5. Interpret interaction pattern

TEMPORAL TREND:
"How has [outcome] changed over [time period]?"
1. [Outcome] by [time units]
2. Test for linear trend
3. Check for seasonal patterns
4. Control for other time-varying factors
5. Statistical significance of trend
